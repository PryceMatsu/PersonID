{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#google drive path\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import datasets, models, transforms\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import json\n",
        "\n",
        "DATA_DIR = '/content/drive/MyDrive/dataset/' #\"train\" & \"validation\" folder locations\n",
        "MODEL_SAVE_PATH_CLASSIFIER = '/content/drive/MyDrive/person_classifier_model.pth' # resnet18 model path\n",
        "CLASSES_SAVE_PATH = '/content/drive/MyDrive/person_reid_classes.json' #storing ben and pryce names in json format (ideal for storing class labels)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #safety net for hardware"
      ],
      "metadata": {
        "id": "v9xQm6O9Gp2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trains images, loads ben/pryce datasets, stores class names\n",
        "\n",
        "input_size = 224 #resnet standard input image size\n",
        "\n",
        "data_transforms = { #dictionary for image processing pipelines\n",
        "    'train': transforms.Compose([ #crops portion of image. the rest are conditions to train & validate images\n",
        "        transforms.RandomResizedCrop(input_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'validation': transforms.Compose([\n",
        "        transforms.Resize(input_size + 32),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "try:\n",
        "    image_datasets = {x: datasets.ImageFolder(os.path.join(DATA_DIR, x), data_transforms[x]) #loading photos/data from \"train\" and \"validation\". ImageFoler auto assigns labels based on folder names\n",
        "                      for x in ['train', 'validation']}\n",
        "    BATCH_SIZE = 16 #num of images processed per training step\n",
        "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE,\n",
        "                                                 shuffle=True, num_workers=2)\n",
        "                  for x in ['train', 'validation']}\n",
        "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'validation']}\n",
        "    class_names = image_datasets['train'].classes #gets folder names as class labels\n",
        "    num_classes = len(class_names)  #counts num of people being trained\n",
        "\n",
        "    with open(CLASSES_SAVE_PATH, 'w') as f:\n",
        "        json.dump(class_names, f) #saves class names to use later on\n",
        "\n",
        "except Exception as e: #error message\n",
        "    print(f\"Error loading data: {e}. Ensure DATA_DIR and subfolder structure are correct.\")"
      ],
      "metadata": {
        "id": "m6jbNc19Jov6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loads pertrained resnet18 model & uses it for ben & pryce\n",
        "\n",
        "def setup_classification_model(num_classes_to_predict): #creates & returns custom resnet model\n",
        "    model_ft = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1) #loading resnet onto imagenet for weight loading\n",
        "    #fine tunes resnet layers\n",
        "    for param in model_ft.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    num_ftrs = model_ft.fc.in_features #size of embedding we'll get later\n",
        "    model_ft.fc = nn.Linear(num_ftrs, num_classes_to_predict) # replaces FC layer with new one\n",
        "    model_ft = model_ft.to(device) #moves model to GPU\n",
        "    return model_ft, num_ftrs\n",
        "\n",
        "if 'num_classes' in locals() or 'num_classes' in globals(): #check for num_classses definition\n",
        "    classification_model, embedding_dim_size = setup_classification_model(num_classes) #calls and stores training model and size of vector\n",
        "else:\n",
        "    print(\"ERROR\")"
      ],
      "metadata": {
        "id": "n9BQNTvnJpC6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepares componenets needed for training\n",
        "if 'classification_model' in locals() or 'classification_model' in globals(): #checks if classification_model already defined\n",
        "    criterion = nn.CrossEntropyLoss() #loss function for training resnet- how wrong predictions are\n",
        "    # Observe that all parameters are being optimized\n",
        "    optimizer_ft = optim.Adam(classification_model.parameters(), lr=0.0001) #adam optimizer for fine tuning model weights\n",
        "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1) #learning rate\n",
        "else:\n",
        "    print(\"classification model ERROR\")"
      ],
      "metadata": {
        "id": "15qpxW-BJpSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TRAINING\n",
        "def train_classification_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time() #to measure runtime later\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0 #initial model weights for later\n",
        "    history = {'train_loss': [], 'train_acc': [], 'validation_loss': [], 'validation_acc': []} #tracking highest validation accuracy\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for phase in ['train', 'validation']: #model learns or validates\n",
        "            if phase == 'train':\n",
        "                model.train() #allows dropout\n",
        "            else:\n",
        "                model.eval() #prevents gradient\n",
        "            #looping over images and labels\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            for inputs, labels in dataloaders[phase]: #returning images\n",
        "                inputs = inputs.to(device) #moves data to GPU\n",
        "                labels = labels.to(device) #moves data to GPU\n",
        "                optimizer.zero_grad()\n",
        "                with torch.set_grad_enabled(phase == 'train'): #computes gradients\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1) #FORWARD PASS\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    #backpropagation for training\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "            #compute & record epochs\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            #average loss & accuracy\n",
        "            history[f'{phase}_loss'].append(epoch_loss)\n",
        "            history[f'{phase}_acc'].append(epoch_acc.item())\n",
        "            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "            #save best model\n",
        "            if phase == 'validation' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                torch.save(model.state_dict(), MODEL_SAVE_PATH_CLASSIFIER)\n",
        "                print(f\"New best validation accuracy: {best_acc:.4f}. Model saved to {MODEL_SAVE_PATH_CLASSIFIER}\")\n",
        "        print()\n",
        "    time_elapsed = time.time() - since\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, history"
      ],
      "metadata": {
        "id": "z7bwKF7xJuvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initiating training process\n",
        "if 'classification_model' in locals() and 'criterion' in locals() and 'optimizer_ft' in locals() and 'exp_lr_scheduler' in locals(): #check all componentns are defined and ready\n",
        "    print(\"starting\")\n",
        "    NUM_EPOCHS = 15 #15-25 good range for fine tuning\n",
        "    #trains and validates models. passes in all components\n",
        "    trained_classification_model, training_history = train_classification_model(\n",
        "        classification_model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=NUM_EPOCHS\n",
        "    )\n",
        "    print(\" training done\")\n",
        "else:\n",
        "    print(\"error in training\")"
      ],
      "metadata": {
        "id": "WRM_qyCFJu2a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}